{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🏠 Room Video to 3D Analysis Pipeline\n",
    "\n",
    "Analyzes full room rotation video to detect all doors and windows.\n",
    "\n",
    "**Requirements:**\n",
    "- Full 360° rotation video starting and ending at the same door\n",
    "- Good lighting and steady camera movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install -q opencv-python numpy matplotlib pillow tqdm scikit-image\n",
    "\n",
    "# Imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from google.colab import files\n",
    "import shutil\n",
    "from skimage import feature, filters, morphology\n",
    "from scipy import ndimage\n",
    "\n",
    "print(\"✅ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload video\n",
    "print(\"📤 Upload your room video (full 360° rotation)\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    filename = list(uploaded.keys())[0]\n",
    "    video_path = \"/content/room_video.mp4\"\n",
    "    shutil.move(filename, video_path)\n",
    "    print(f\"✅ Video saved to: {video_path}\")\n",
    "else:\n",
    "    print(\"❌ No video uploaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Frames (More Dense Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, num_frames=60):  # Increased to 60 frames\n",
    "    \"\"\"Extract frames at regular intervals for full room coverage\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    duration = total_frames / fps\n",
    "    interval = max(1, total_frames // num_frames)\n",
    "    \n",
    "    print(f\"📹 Video info: {duration:.1f}s, {total_frames} total frames\")\n",
    "    print(f\"📸 Extracting frame every {interval} frames ({duration/num_frames:.1f}s)\")\n",
    "    \n",
    "    frames = []\n",
    "    for i in range(0, total_frames, interval):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append({\n",
    "                'frame_num': i,\n",
    "                'time': i / fps,\n",
    "                'image': cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            })\n",
    "            if len(frames) >= num_frames:\n",
    "                break\n",
    "    \n",
    "    cap.release()\n",
    "    print(f\"✅ Extracted {len(frames)} frames for analysis\")\n",
    "    \n",
    "    # Show first, middle, and last frames\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    key_frames = [0, len(frames)//2, len(frames)-1]\n",
    "    titles = [\"First Frame (Start Door)\", \"Middle Frame\", \"Last Frame (Same Door)\"]\n",
    "    \n",
    "    for idx, (frame_idx, title) in enumerate(zip(key_frames, titles)):\n",
    "        axes[idx].imshow(frames[frame_idx]['image'])\n",
    "        axes[idx].set_title(f\"{title}\\nt={frames[frame_idx]['time']:.1f}s\")\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return frames\n",
    "\n",
    "frames = extract_frames(video_path, num_frames=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Confidence Door & Window Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_door_features(image):\n",
    "    \"\"\"Comprehensive door detection with multiple feature checks\"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Enhanced preprocessing\n",
    "    denoised = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(denoised)\n",
    "    \n",
    "    # Multi-scale edge detection\n",
    "    edges_fine = cv2.Canny(enhanced, 30, 90)\n",
    "    edges_coarse = cv2.Canny(enhanced, 50, 150)\n",
    "    edges_combined = cv2.bitwise_or(edges_fine, edges_coarse)\n",
    "    \n",
    "    # Detect strong vertical lines (door frames)\n",
    "    lines = cv2.HoughLinesP(edges_combined, 1, np.pi/180, 80, \n",
    "                           minLineLength=height*0.3, maxLineGap=20)\n",
    "    \n",
    "    vertical_lines = []\n",
    "    horizontal_lines = []\n",
    "    \n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)\n",
    "            line_length = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "            \n",
    "            if angle > 85 or angle < 5:  # Vertical lines\n",
    "                vertical_lines.append((x1, y1, x2, y2, line_length))\n",
    "            elif 85 < angle < 95:  # Horizontal lines\n",
    "                horizontal_lines.append((x1, y1, x2, y2, line_length))\n",
    "    \n",
    "    # Create feature maps\n",
    "    vertical_map = np.zeros((height, width), dtype=np.uint8)\n",
    "    for x1, y1, x2, y2, _ in vertical_lines:\n",
    "        cv2.line(vertical_map, (x1, y1), (x2, y2), 255, 3)\n",
    "    \n",
    "    # Morphological operations to connect door components\n",
    "    kernel_close = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))\n",
    "    connected = cv2.morphologyEx(edges_combined, cv2.MORPH_CLOSE, kernel_close)\n",
    "    \n",
    "    # Fill regions between vertical lines\n",
    "    filled = cv2.bitwise_or(connected, vertical_map)\n",
    "    kernel_fill = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 20))\n",
    "    filled = cv2.morphologyEx(filled, cv2.MORPH_CLOSE, kernel_fill)\n",
    "    \n",
    "    return filled, vertical_lines, edges_combined\n",
    "\n",
    "def refine_door_boundaries(image, initial_bbox):\n",
    "    \"\"\"Use GrabCut-like algorithm to refine door boundaries for precise segmentation\"\"\"\n",
    "    x, y, w, h = initial_bbox\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Expand bbox slightly for GrabCut initialization\n",
    "    margin = 10\n",
    "    x1 = max(0, x - margin)\n",
    "    y1 = max(0, y - margin)\n",
    "    x2 = min(width, x + w + margin)\n",
    "    y2 = min(height, y + h + margin)\n",
    "    \n",
    "    # Create mask for GrabCut\n",
    "    mask = np.zeros((height, width), np.uint8)\n",
    "    mask[y1:y2, x1:x2] = cv2.GC_PR_FGD  # Probable foreground\n",
    "    mask[y:y+h, x:x+w] = cv2.GC_FGD     # Definite foreground\n",
    "    \n",
    "    # Initialize foreground and background models\n",
    "    bgd_model = np.zeros((1, 65), np.float64)\n",
    "    fgd_model = np.zeros((1, 65), np.float64)\n",
    "    \n",
    "    # Apply GrabCut\n",
    "    rect = (x1, y1, x2-x1, y2-y1)\n",
    "    try:\n",
    "        cv2.grabCut(image, mask, rect, bgd_model, fgd_model, 3, cv2.GC_INIT_WITH_MASK)\n",
    "    except:\n",
    "        # If GrabCut fails, return original bbox\n",
    "        return initial_bbox\n",
    "    \n",
    "    # Extract foreground\n",
    "    mask2 = np.where((mask == cv2.GC_FGD) | (mask == cv2.GC_PR_FGD), 255, 0).astype('uint8')\n",
    "    \n",
    "    # Find precise contour\n",
    "    contours, _ = cv2.findContours(mask2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        # Get the largest contour\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        \n",
    "        # Validate the refined bbox\n",
    "        if w > 50 and h > 100:  # Minimum door size\n",
    "            return [x, y, w, h]\n",
    "    \n",
    "    return initial_bbox\n",
    "\n",
    "def find_door_edges(image, bbox):\n",
    "    \"\"\"Find precise door edges using edge detection within bbox\"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    \n",
    "    # Extract door region\n",
    "    door_region = image[y:y+h, x:x+w]\n",
    "    gray_region = cv2.cvtColor(door_region, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply edge detection\n",
    "    edges = cv2.Canny(gray_region, 50, 150)\n",
    "    \n",
    "    # Find vertical edges (door frame)\n",
    "    vertical_kernel = np.array([[-1, 0, 1]], dtype=np.float32)\n",
    "    vertical_edges = cv2.filter2D(gray_region, -1, vertical_kernel)\n",
    "    vertical_edges = np.abs(vertical_edges)\n",
    "    \n",
    "    # Find leftmost and rightmost strong edges\n",
    "    edge_threshold = np.max(vertical_edges) * 0.3\n",
    "    strong_edges = vertical_edges > edge_threshold\n",
    "    \n",
    "    # Find bounds\n",
    "    left_bound = x\n",
    "    right_bound = x + w\n",
    "    \n",
    "    # Scan from left to find first strong vertical edge\n",
    "    for i in range(w//4):  # Only scan first quarter\n",
    "        if np.sum(strong_edges[:, i]) > h * 0.5:  # Strong vertical edge\n",
    "            left_bound = x + i\n",
    "            break\n",
    "    \n",
    "    # Scan from right to find last strong vertical edge\n",
    "    for i in range(w-1, 3*w//4, -1):  # Only scan last quarter\n",
    "        if np.sum(strong_edges[:, i]) > h * 0.5:  # Strong vertical edge\n",
    "            right_bound = x + i\n",
    "            break\n",
    "    \n",
    "    # Return refined bbox\n",
    "    refined_width = right_bound - left_bound\n",
    "    if refined_width > 50:  # Minimum door width\n",
    "        return [left_bound, y, refined_width, h]\n",
    "    \n",
    "    return bbox\n",
    "\n",
    "def calculate_door_confidence(bbox, vertical_lines, image_shape, is_edge_frame=False):\n",
    "    \"\"\"Calculate confidence score for door detection\"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    height, width = image_shape[:2]\n",
    "    \n",
    "    confidence = 0.0\n",
    "    \n",
    "    # Feature 1: Aspect ratio (doors are tall)\n",
    "    aspect_ratio = h / w if w > 0 else 0\n",
    "    if 1.8 < aspect_ratio < 3.5:\n",
    "        confidence += 0.25\n",
    "    elif 1.5 < aspect_ratio < 4.0:\n",
    "        confidence += 0.15\n",
    "    \n",
    "    # Feature 2: Height relative to image\n",
    "    height_ratio = h / height\n",
    "    if height_ratio > 0.5:\n",
    "        confidence += 0.2\n",
    "    elif height_ratio > 0.4:\n",
    "        confidence += 0.15\n",
    "    \n",
    "    # Feature 3: Bottom position (doors reach floor)\n",
    "    bottom_position = (y + h) / height\n",
    "    if bottom_position > 0.9:\n",
    "        confidence += 0.25\n",
    "    elif bottom_position > 0.85:\n",
    "        confidence += 0.2\n",
    "    \n",
    "    # Feature 4: Vertical lines within bbox\n",
    "    vertical_count = 0\n",
    "    for vx1, vy1, vx2, vy2, length in vertical_lines:\n",
    "        # Check if vertical line is within door bbox\n",
    "        if (x <= vx1 <= x+w and x <= vx2 <= x+w and\n",
    "            y <= vy1 <= y+h and y <= vy2 <= y+h and\n",
    "            length > h * 0.5):\n",
    "            vertical_count += 1\n",
    "    \n",
    "    if vertical_count >= 2:  # At least 2 strong vertical lines\n",
    "        confidence += 0.3\n",
    "    elif vertical_count >= 1:\n",
    "        confidence += 0.15\n",
    "    \n",
    "    # Special handling for first/last frames - be more lenient\n",
    "    if is_edge_frame:\n",
    "        # If it looks like a door (tall, reaches floor), boost confidence\n",
    "        if aspect_ratio > 1.5 and bottom_position > 0.8 and height_ratio > 0.35:\n",
    "            confidence += 0.15  # Edge frame bonus\n",
    "    \n",
    "    return min(confidence, 1.0)\n",
    "\n",
    "def detect_doors_windows_confident(image, confidence_threshold=0.9, is_edge_frame=False):\n",
    "    \"\"\"Detect doors and windows with high confidence and precise boundaries\"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Get door features\n",
    "    door_mask, vertical_lines, edges = detect_door_features(image)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(door_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    doors = []\n",
    "    windows = []\n",
    "    \n",
    "    # Adjust threshold for edge frames\n",
    "    effective_threshold = confidence_threshold - 0.1 if is_edge_frame else confidence_threshold\n",
    "    \n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area < width * height * 0.02:  # Minimum size\n",
    "            continue\n",
    "        \n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        initial_bbox = [x, y, w, h]\n",
    "        \n",
    "        # Calculate door confidence\n",
    "        confidence = calculate_door_confidence(initial_bbox, vertical_lines, image.shape, is_edge_frame)\n",
    "        \n",
    "        if confidence >= effective_threshold:\n",
    "            # Refine the bounding box for precise door boundaries\n",
    "            refined_bbox = find_door_edges(image, initial_bbox)\n",
    "            \n",
    "            # Further refine with GrabCut for very precise segmentation\n",
    "            if confidence >= 0.85:  # Only for high confidence doors\n",
    "                refined_bbox = refine_door_boundaries(image, refined_bbox)\n",
    "            \n",
    "            x, y, w, h = refined_bbox\n",
    "            doors.append({\n",
    "                'bbox': [x, y, x+w, y+h],\n",
    "                'confidence': confidence,\n",
    "                'width': w,\n",
    "                'height': h,\n",
    "                'aspect_ratio': h/w if w > 0 else 0\n",
    "            })\n",
    "        elif confidence >= 0.5 and h/w < 1.5:  # Potential window\n",
    "            bottom_pos = (y + h) / height\n",
    "            if bottom_pos < 0.8 and y > height * 0.1:\n",
    "                windows.append({\n",
    "                    'bbox': [x, y, x+w, y+h],\n",
    "                    'confidence': confidence * 0.8,  # Lower confidence for windows\n",
    "                    'width': w,\n",
    "                    'height': h\n",
    "                })\n",
    "    \n",
    "    # Remove overlapping detections\n",
    "    doors = remove_overlapping(doors, iou_threshold=0.3)\n",
    "    windows = remove_overlapping(windows, iou_threshold=0.3)\n",
    "    \n",
    "    return doors, windows, door_mask\n",
    "\n",
    "def remove_overlapping(detections, iou_threshold=0.3):\n",
    "    \"\"\"Remove overlapping detections, keeping highest confidence\"\"\"\n",
    "    if not detections:\n",
    "        return []\n",
    "    \n",
    "    detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n",
    "    keep = []\n",
    "    \n",
    "    for det in detections:\n",
    "        overlap = False\n",
    "        for kept in keep:\n",
    "            if calculate_iou(det['bbox'], kept['bbox']) > iou_threshold:\n",
    "                overlap = True\n",
    "                break\n",
    "        if not overlap:\n",
    "            keep.append(det)\n",
    "    \n",
    "    return keep\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calculate intersection over union\"\"\"\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    \n",
    "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection / union if union > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze All Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all frames with high confidence threshold\n",
    "print(\"🚀 Analyzing all frames with 90% confidence threshold...\")\n",
    "print(\"📌 First and last 5 frames will be scanned more thoroughly for the main door\\n\")\n",
    "\n",
    "all_detections = []\n",
    "confidence_threshold = 0.9\n",
    "\n",
    "for i, frame in enumerate(tqdm(frames, desc=\"Processing frames\")):\n",
    "    # Check if this is an edge frame (first or last 5 frames)\n",
    "    is_edge_frame = (i < 5) or (i >= len(frames) - 5)\n",
    "    \n",
    "    doors, windows, _ = detect_doors_windows_confident(frame['image'], confidence_threshold, is_edge_frame)\n",
    "    all_detections.append({\n",
    "        'frame_num': frame['frame_num'],\n",
    "        'time': frame['time'],\n",
    "        'doors': doors,\n",
    "        'windows': windows\n",
    "    })\n",
    "\n",
    "# Statistics\n",
    "door_counts = [len(d['doors']) for d in all_detections]\n",
    "window_counts = [len(d['windows']) for d in all_detections]\n",
    "total_doors = sum(door_counts)\n",
    "total_windows = sum(window_counts)\n",
    "frames_with_doors = sum(1 for c in door_counts if c > 0)\n",
    "frames_with_windows = sum(1 for c in window_counts if c > 0)\n",
    "\n",
    "print(f\"\\n📊 Detection Summary (≥90% confidence):\")\n",
    "print(f\"  Total door detections: {total_doors}\")\n",
    "print(f\"  Frames with doors: {frames_with_doors}/{len(frames)} ({frames_with_doors/len(frames)*100:.0f}%)\")\n",
    "print(f\"  Total window detections: {total_windows}\")\n",
    "print(f\"  Frames with windows: {frames_with_windows}/{len(frames)} ({frames_with_windows/len(frames)*100:.0f}%)\")\n",
    "\n",
    "# Check first and last frame\n",
    "first_door = len(all_detections[0]['doors']) > 0\n",
    "last_door = len(all_detections[-1]['doors']) > 0\n",
    "\n",
    "# Check if the same door (compare bounding boxes)\n",
    "same_door = False\n",
    "if first_door and last_door:\n",
    "    first_bbox = all_detections[0]['doors'][0]['bbox']\n",
    "    last_bbox = all_detections[-1]['doors'][0]['bbox']\n",
    "    \n",
    "    # Calculate similarity (doors should be in similar position)\n",
    "    x_diff = abs((first_bbox[0] + first_bbox[2])/2 - (last_bbox[0] + last_bbox[2])/2)\n",
    "    y_diff = abs((first_bbox[1] + first_bbox[3])/2 - (last_bbox[1] + last_bbox[3])/2)\n",
    "    \n",
    "    # If centers are within 20% of image width/height, consider it the same door\n",
    "    img_width = frames[0]['image'].shape[1]\n",
    "    img_height = frames[0]['image'].shape[0]\n",
    "    same_door = (x_diff < img_width * 0.2) and (y_diff < img_height * 0.2)\n",
    "\n",
    "print(f\"\\n🚪 Door continuity check:\")\n",
    "print(f\"  First frame has door: {'✅' if first_door else '❌'}\")\n",
    "print(f\"  Last frame has door: {'✅' if last_door else '❌'}\")\n",
    "print(f\"  Same door detected: {'✅' if same_door else '❌ (different positions)' if first_door and last_door else '❌'}\")\n",
    "\n",
    "# If no door in first/last frames, show them for debugging\n",
    "if not first_door or not last_door:\n",
    "    print(\"\\n⚠️ Main door not detected in edge frames! Showing frames for review...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    if not first_door:\n",
    "        axes[0].imshow(frames[0]['image'])\n",
    "        axes[0].set_title(\"First Frame - No door detected\")\n",
    "        axes[0].axis('off')\n",
    "    else:\n",
    "        axes[0].axis('off')\n",
    "        axes[0].text(0.5, 0.5, \"First frame OK\", ha='center', va='center')\n",
    "    \n",
    "    if not last_door:\n",
    "        axes[1].imshow(frames[-1]['image'])\n",
    "        axes[1].set_title(\"Last Frame - No door detected\")\n",
    "        axes[1].axis('off')\n",
    "    else:\n",
    "        axes[1].axis('off')\n",
    "        axes[1].text(0.5, 0.5, \"Last frame OK\", ha='center', va='center')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Detection Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot detection timeline\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "times = [f['time'] for f in frames]\n",
    "\n",
    "# Door detections\n",
    "ax1.plot(times, door_counts, 'r-', linewidth=2)\n",
    "ax1.fill_between(times, door_counts, alpha=0.3, color='red')\n",
    "ax1.set_ylabel('Number of Doors')\n",
    "ax1.set_title('Door Detections Throughout 360° Room Scan')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(bottom=0)\n",
    "\n",
    "# Mark first and last frames\n",
    "ax1.axvline(x=times[0], color='green', linestyle='--', alpha=0.7, label='Start')\n",
    "ax1.axvline(x=times[-1], color='green', linestyle='--', alpha=0.7, label='End')\n",
    "ax1.legend()\n",
    "\n",
    "# Window detections\n",
    "ax2.plot(times, window_counts, 'b-', linewidth=2)\n",
    "ax2.fill_between(times, window_counts, alpha=0.3, color='blue')\n",
    "ax2.set_ylabel('Number of Windows')\n",
    "ax2.set_xlabel('Time (seconds)')\n",
    "ax2.set_title('Window Detections Throughout 360° Room Scan')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(bottom=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show High-Confidence Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detection(image, doors, windows, title=\"\"):\n",
    "    \"\"\"Visualize detection results\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    # Draw doors (red)\n",
    "    for door in doors:\n",
    "        bbox = door['bbox']\n",
    "        rect = patches.Rectangle((bbox[0], bbox[1]), \n",
    "                               bbox[2]-bbox[0], bbox[3]-bbox[1],\n",
    "                               linewidth=3, edgecolor='red', facecolor='none')\n",
    "        plt.gca().add_patch(rect)\n",
    "        plt.text(bbox[0], bbox[1]-5, f\"Door {door['confidence']:.2f}\", \n",
    "                color='red', fontweight='bold', fontsize=12,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
    "    \n",
    "    # Draw windows (blue)\n",
    "    for window in windows:\n",
    "        bbox = window['bbox']\n",
    "        rect = patches.Rectangle((bbox[0], bbox[1]), \n",
    "                               bbox[2]-bbox[0], bbox[3]-bbox[1],\n",
    "                               linewidth=3, edgecolor='blue', facecolor='none')\n",
    "        plt.gca().add_patch(rect)\n",
    "        plt.text(bbox[0], bbox[1]-5, f\"Window {window['confidence']:.2f}\", \n",
    "                color='blue', fontweight='bold', fontsize=12,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"cyan\", alpha=0.7))\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show frames with high-confidence door detections\n",
    "door_frames = [(i, d) for i, d in enumerate(all_detections) if len(d['doors']) > 0]\n",
    "\n",
    "if door_frames:\n",
    "    print(f\"\\n🚪 Found {len(door_frames)} frames with high-confidence doors (≥90%)\\n\")\n",
    "    \n",
    "    # Show first few door detections\n",
    "    for idx, (frame_idx, detection) in enumerate(door_frames[:5]):\n",
    "        frame = frames[frame_idx]\n",
    "        visualize_detection(frame['image'], detection['doors'], detection['windows'],\n",
    "                          f\"Frame {frame_idx} (t={frame['time']:.1f}s) - Door Detection #{idx+1}\")\n",
    "else:\n",
    "    print(\"❌ No doors detected with ≥90% confidence!\")\n",
    "\n",
    "# Show frames with windows\n",
    "window_frames = [(i, d) for i, d in enumerate(all_detections) if len(d['windows']) > 0]\n",
    "if window_frames:\n",
    "    print(f\"\\n🪟 Found {len(window_frames)} frames with windows\\n\")\n",
    "    for idx, (frame_idx, detection) in enumerate(window_frames[:3]):\n",
    "        frame = frames[frame_idx]\n",
    "        visualize_detection(frame['image'], detection['doors'], detection['windows'],\n",
    "                          f\"Frame {frame_idx} (t={frame['time']:.1f}s) - Window Detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Door/Window Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate unique doors and windows (accounting for rotation)\n",
    "def estimate_unique_features(detections, frames_per_rotation=None):\n",
    "    \"\"\"Estimate unique doors/windows in the room\"\"\"\n",
    "    if frames_per_rotation is None:\n",
    "        frames_per_rotation = len(detections)\n",
    "    \n",
    "    # Group detections by approximate position in rotation\n",
    "    rotation_segments = 8  # Divide rotation into 8 segments\n",
    "    segment_size = frames_per_rotation // rotation_segments\n",
    "    \n",
    "    door_segments = set()\n",
    "    window_segments = set()\n",
    "    \n",
    "    for i, det in enumerate(detections):\n",
    "        segment = i // segment_size\n",
    "        if det['doors']:\n",
    "            door_segments.add(segment)\n",
    "        if det['windows']:\n",
    "            window_segments.add(segment)\n",
    "    \n",
    "    return len(door_segments), len(window_segments)\n",
    "\n",
    "unique_doors, unique_windows = estimate_unique_features(all_detections)\n",
    "\n",
    "print(f\"\\n🏠 Room Features Summary:\")\n",
    "print(f\"  Estimated unique doors: {unique_doors}\")\n",
    "print(f\"  Estimated unique windows: {unique_windows}\")\n",
    "print(f\"\\n📐 Room layout:\")\n",
    "print(f\"  Main entrance/exit: {'✅ Detected' if first_door and last_door else '❌ Not detected'}\")\n",
    "if unique_doors > 1:\n",
    "    print(f\"  Additional doors: {unique_doors - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export comprehensive results\n",
    "export_data = {\n",
    "    'video_info': {\n",
    "        'total_frames': len(frames),\n",
    "        'confidence_threshold': confidence_threshold,\n",
    "        'rotation': '360_degrees'\n",
    "    },\n",
    "    'summary': {\n",
    "        'total_door_detections': total_doors,\n",
    "        'total_window_detections': total_windows,\n",
    "        'frames_with_doors': frames_with_doors,\n",
    "        'frames_with_windows': frames_with_windows,\n",
    "        'estimated_unique_doors': unique_doors,\n",
    "        'estimated_unique_windows': unique_windows,\n",
    "        'main_door_detected': first_door and last_door\n",
    "    },\n",
    "    'detections': all_detections\n",
    "}\n",
    "\n",
    "output_path = '/content/door_window_detections_360.json'\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(export_data, f, indent=2)\n",
    "\n",
    "files.download(output_path)\n",
    "print(f\"\\n✅ Results exported to: {output_path}\")\n",
    "print(f\"\\n📋 Detection summary:\")\n",
    "print(f\"  - {unique_doors} unique door(s) detected\")\n",
    "print(f\"  - {unique_windows} unique window(s) detected\")\n",
    "print(f\"  - Main door (start/end): {'✅' if first_door and last_door else '❌'}\")\n",
    "print(f\"  - All detections use ≥90% confidence threshold\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
