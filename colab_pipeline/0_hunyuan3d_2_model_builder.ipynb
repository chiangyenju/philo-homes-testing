{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hunyuan3D 2.0 - Furniture to 3D Models\n",
    "\n",
    "Convert furniture images (with transparent backgrounds) into 3D GLB models.\n",
    "\n",
    "**Note:** If Hunyuan3D-2 setup is complex, consider using the `simple_3d_generator.ipynb` notebook instead, which uses Shap-E or TripoSR.\n",
    "\n",
    "**Setup:** Runtime â†’ Change runtime type â†’ GPU (T4 or better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q transformers accelerate diffusers\n",
    "!pip install -q trimesh pygltflib pillow numpy gradio\n",
    "\n",
    "# Clone Hunyuan3D\n",
    "!git clone -q https://github.com/Tencent-Hunyuan/Hunyuan3D-2.git\n",
    "!cd Hunyuan3D-2 && pip install -q -r requirements.txt\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/Hunyuan3D-2')\n",
    "print(\"âœ… Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and download model\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Drive\n",
    "drive.mount('/content/drive')\n",
    "INPUT_DIR = '/content/drive/MyDrive/furniture_images/background_removed'\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/furniture_images/3d_models'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Check what's in the Hunyuan3D-2 directory\n",
    "!ls -la /content/Hunyuan3D-2/\n",
    "\n",
    "# Download model weights from Hugging Face\n",
    "print(\"Downloading Hunyuan3D model weights...\")\n",
    "!mkdir -p /content/models\n",
    "# Using the official Hugging Face model\n",
    "!cd /content/models && wget -c https://huggingface.co/Tencent/Hunyuan3D-2/resolve/main/hunyuan3d-2.0.ckpt\n",
    "\n",
    "print(\"âœ… Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D generation interface\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "\n",
    "# First, let's check the repository structure\n",
    "import sys\n",
    "sys.path.append('/content/Hunyuan3D-2')\n",
    "\n",
    "# Try to find the correct import path\n",
    "try:\n",
    "    # Check if there's an app.py or main inference script\n",
    "    !cd /content/Hunyuan3D-2 && find . -name \"*.py\" | grep -E \"(app|main|inference)\" | head -10\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# For now, let's use a simpler approach with the actual Hunyuan3D API\n",
    "# Based on the repository, it seems to use a different structure\n",
    "\n",
    "def generate_3d_model(image, quality=\"Standard\"):\n",
    "    \"\"\"\n",
    "    Generate 3D model from image using Hunyuan3D-2\n",
    "    \"\"\"\n",
    "    if image is None:\n",
    "        return None, None, \"Please upload an image\"\n",
    "    \n",
    "    # Save input image temporarily\n",
    "    temp_input = \"/content/temp_input.png\"\n",
    "    image.save(temp_input)\n",
    "    \n",
    "    # Quality settings\n",
    "    quality_map = {\n",
    "        \"Fast\": \"--steps 30\",\n",
    "        \"Standard\": \"--steps 50\", \n",
    "        \"High\": \"--steps 100\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Run Hunyuan3D command\n",
    "        output_name = f\"model_{len(os.listdir(OUTPUT_DIR))}\"\n",
    "        output_path = f\"{OUTPUT_DIR}/{output_name}.glb\"\n",
    "        \n",
    "        # Execute the model (adjust command based on actual repo structure)\n",
    "        !cd /content/Hunyuan3D-2 && python app.py \\\n",
    "            --input {temp_input} \\\n",
    "            --output {output_path} \\\n",
    "            --model_path /content/models/hunyuan3d-2.0.ckpt \\\n",
    "            {quality_map[quality]}\n",
    "        \n",
    "        # Create a preview image\n",
    "        preview = image  # For now, use input as preview\n",
    "        \n",
    "        return preview, output_path, f\"âœ… Saved to {output_path}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, None, f\"Error: {str(e)}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "with gr.Blocks(title=\"Hunyuan3D\") as app:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # ðŸŽ¯ Furniture â†’ 3D Model\n",
    "    \n",
    "    Convert furniture images with transparent backgrounds into 3D models.\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            input_img = gr.Image(type=\"pil\", label=\"Upload Furniture Image\")\n",
    "            quality = gr.Radio([\"Fast\", \"Standard\", \"High\"], value=\"Standard\", label=\"Quality\")\n",
    "            generate_btn = gr.Button(\"Generate 3D Model\", variant=\"primary\")\n",
    "            status = gr.Textbox(label=\"Status\")\n",
    "            \n",
    "        with gr.Column():\n",
    "            preview = gr.Image(label=\"Preview\")\n",
    "            download = gr.File(label=\"Download GLB\")\n",
    "    \n",
    "    generate_btn.click(\n",
    "        generate_3d_model,\n",
    "        inputs=[input_img, quality],\n",
    "        outputs=[preview, download, status]\n",
    "    )\n",
    "    \n",
    "    # Load examples\n",
    "    import glob\n",
    "    examples = glob.glob(f\"{INPUT_DIR}/*.png\")[:3]\n",
    "    if examples:\n",
    "        gr.Examples(examples=[[ex] for ex in examples], inputs=[input_img])\n",
    "\n",
    "# First, let's check what files are available in the repo\n",
    "print(\"Checking Hunyuan3D-2 repository structure...\")\n",
    "!cd /content/Hunyuan3D-2 && ls -la\n",
    "\n",
    "app.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing (optional)\n",
    "def batch_convert(folder_path=INPUT_DIR, quality=\"Standard\"):\n",
    "    import glob\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    images = glob.glob(f\"{folder_path}/*.png\")\n",
    "    print(f\"Found {len(images)} images\")\n",
    "    \n",
    "    for img_path in tqdm(images):\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            _, path, _ = generate_3d(img, quality)\n",
    "            print(f\"âœ“ {os.path.basename(img_path)} â†’ {os.path.basename(path)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— {os.path.basename(img_path)}: {e}\")\n",
    "\n",
    "# Run batch: batch_convert(quality=\"Fast\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
