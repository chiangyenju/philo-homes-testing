{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDXL Inpainting with Google Drive Models\n",
    "\n",
    "Uses pre-downloaded models from your Drive - no downloading needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Check if models exist\n",
    "import os\n",
    "model_path = '/content/drive/MyDrive/inpainting_models/'\n",
    "if os.path.exists(model_path):\n",
    "    print(\"✅ Models found in Drive\")\n",
    "    print(\"Available models:\", os.listdir(model_path))\n",
    "else:\n",
    "    print(\"❌ Models not found. Please run download_inpainting_models.py locally first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install minimal dependencies\n",
    "!pip install diffusers transformers accelerate safetensors pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SDXL from your Drive\n",
    "from diffusers import AutoPipelineForInpainting\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load from Drive (no downloading!)\n",
    "pipe = AutoPipelineForInpainting.from_pretrained(\n",
    "    \"/content/drive/MyDrive/inpainting_models/sdxl_inpainting\",\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\",\n",
    "    local_files_only=True  # Don't download, use local files\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Optimize for speed\n",
    "pipe.enable_xformers_memory_efficient_attention()\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "print(\"✅ SDXL model loaded from Drive!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your exported files\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "print(\"Upload the zip file from room_removal_ultimate.py export\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract\n",
    "zip_name = list(uploaded.keys())[0]\n",
    "with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "\n",
    "# Load images\n",
    "image = Image.open(\"image.png\").convert(\"RGB\")\n",
    "mask = Image.open(\"mask.png\").convert(\"L\")\n",
    "\n",
    "print(f\"Image size: {image.size}\")\n",
    "print(f\"Mask size: {mask.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced inpainting with multiple passes for best quality\n",
    "def high_quality_inpaint(image, mask, prompt=None, num_passes=2):\n",
    "    \"\"\"\n",
    "    Multi-pass inpainting for highest quality\n",
    "    \"\"\"\n",
    "    result = image\n",
    "    \n",
    "    # Auto-generate prompt if not provided\n",
    "    if prompt is None:\n",
    "        prompt = \"high quality interior, empty room, professional photography, clean walls and floor\"\n",
    "    \n",
    "    for pass_num in range(num_passes):\n",
    "        print(f\"Pass {pass_num + 1}/{num_passes}...\")\n",
    "        \n",
    "        # Adjust strength for each pass\n",
    "        strength = 0.99 if pass_num == 0 else 0.85\n",
    "        \n",
    "        result = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=\"furniture, objects, people, artifacts, blurry, distorted\",\n",
    "            image=result,\n",
    "            mask_image=mask,\n",
    "            num_inference_steps=50,\n",
    "            strength=strength,\n",
    "            guidance_scale=8.0,\n",
    "            height=image.height,\n",
    "            width=image.width\n",
    "        ).images[0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Run high-quality inpainting\n",
    "result = high_quality_inpaint(image, mask)\n",
    "print(\"✅ Inpainting complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title('Original', fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(mask, cmap='gray')\n",
    "axes[1].set_title('Mask', fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(result)\n",
    "axes[2].set_title('SDXL Inpainted (High Quality)', fontsize=14)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save and download\n",
    "result.save(\"result_sdxl_hq.png\")\n",
    "files.download(\"result_sdxl_hq.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Batch processing for multiple images\n",
    "def batch_process(zip_file_path):\n",
    "    \"\"\"\n",
    "    Process multiple image/mask pairs\n",
    "    \"\"\"\n",
    "    import zipfile\n",
    "    import os\n",
    "    \n",
    "    results = []\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('batch')\n",
    "    \n",
    "    # Find all image/mask pairs\n",
    "    for file in os.listdir('batch'):\n",
    "        if file.startswith('image') and file.endswith('.png'):\n",
    "            img_path = f'batch/{file}'\n",
    "            mask_path = img_path.replace('image', 'mask')\n",
    "            \n",
    "            if os.path.exists(mask_path):\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                msk = Image.open(mask_path).convert('L')\n",
    "                \n",
    "                result = high_quality_inpaint(img, msk)\n",
    "                result_path = f'results/{file}'\n",
    "                result.save(result_path)\n",
    "                results.append(result_path)\n",
    "                print(f\"Processed: {file}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Uncomment to use batch processing\n",
    "# results = batch_process('your_batch.zip')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}