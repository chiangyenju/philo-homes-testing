{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Inpainting Notebook\n",
    "\n",
    "Works with SDXL or SD 1.5, from Google Drive or fresh download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "\n",
    "# Check what models are available in Drive\n",
    "models_available = []\n",
    "if os.path.exists('/content/drive/MyDrive/inpainting_models/sdxl_inpainting/'):\n",
    "    print(\"✅ SDXL found in Drive (5.5GB model)\")\n",
    "    models_available.append('sdxl')\n",
    "if os.path.exists('/content/drive/MyDrive/inpainting_models/sd15_inpaint/'):\n",
    "    print(\"✅ SD 1.5 found in Drive (2GB model)\")\n",
    "    models_available.append('sd15')\n",
    "\n",
    "if not models_available:\n",
    "    print(\"❌ No models found in Drive\")\n",
    "    print(\"\\nYou can either:\")\n",
    "    print(\"1. Upload models to Drive first (recommended)\")\n",
    "    print(\"2. Download directly in Colab (will re-download each session)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q diffusers transformers accelerate safetensors pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose and load model\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# SELECT YOUR MODEL HERE\n",
    "MODEL_CHOICE = \"sdxl\"  # Change to \"sd15\" for SD 1.5, or \"download_sdxl\" to download fresh\n",
    "\n",
    "pipe = None\n",
    "\n",
    "if MODEL_CHOICE == \"sdxl\" and 'sdxl' in models_available:\n",
    "    print(\"Loading SDXL from Drive...\")\n",
    "    from diffusers import AutoPipelineForInpainting\n",
    "    pipe = AutoPipelineForInpainting.from_pretrained(\n",
    "        \"/content/drive/MyDrive/inpainting_models/sdxl_inpainting\",\n",
    "        torch_dtype=torch.float16,\n",
    "        variant=\"fp16\",\n",
    "        local_files_only=True\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "elif MODEL_CHOICE == \"sd15\" and 'sd15' in models_available:\n",
    "    print(\"Loading SD 1.5 from Drive...\")\n",
    "    from diffusers import StableDiffusionInpaintPipeline\n",
    "    pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "        \"/content/drive/MyDrive/inpainting_models/sd15_inpaint\",\n",
    "        torch_dtype=torch.float16,\n",
    "        local_files_only=True\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "elif MODEL_CHOICE == \"download_sdxl\":\n",
    "    print(\"Downloading SDXL (this will take time)...\")\n",
    "    from diffusers import AutoPipelineForInpainting\n",
    "    pipe = AutoPipelineForInpainting.from_pretrained(\n",
    "        \"diffusers/stable-diffusion-xl-1.0-inpainting-0.1\",\n",
    "        torch_dtype=torch.float16,\n",
    "        variant=\"fp16\"\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "elif MODEL_CHOICE == \"download_sd15\":\n",
    "    print(\"Downloading SD 1.5 (faster than SDXL)...\")\n",
    "    from diffusers import StableDiffusionInpaintPipeline\n",
    "    pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "        \"runwayml/stable-diffusion-inpainting\",\n",
    "        torch_dtype=torch.float16\n",
    "    ).to(\"cuda\")\n",
    "else:\n",
    "    print(f\"❌ Model '{MODEL_CHOICE}' not found in Drive!\")\n",
    "    print(\"Change MODEL_CHOICE to 'download_sdxl' or 'download_sd15' to download\")\n",
    "\n",
    "if pipe:\n",
    "    # Optimize memory\n",
    "    pipe.enable_xformers_memory_efficient_attention()\n",
    "    if \"sdxl\" in MODEL_CHOICE:\n",
    "        pipe.enable_model_cpu_offload()\n",
    "    print(\"✅ Model loaded and ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your image and mask\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "print(\"Upload the zip file from room_removal_ultimate.py export\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract\n",
    "zip_name = list(uploaded.keys())[0]\n",
    "with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "\n",
    "# Load images\n",
    "image = Image.open(\"image.png\").convert(\"RGB\")\n",
    "mask = Image.open(\"mask.png\").convert(\"L\")\n",
    "\n",
    "print(f\"Loaded: Image {image.size}, Mask {mask.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inpainting\n",
    "if pipe is None:\n",
    "    print(\"❌ No model loaded! Go back and load a model first.\")\n",
    "else:\n",
    "    # Adjust parameters based on model\n",
    "    if \"sdxl\" in MODEL_CHOICE:\n",
    "        # SDXL parameters\n",
    "        result = pipe(\n",
    "            prompt=\"high quality interior, empty room, professional real estate photography, clean walls and floor\",\n",
    "            negative_prompt=\"furniture, objects, people, artifacts, blurry, distorted\",\n",
    "            image=image,\n",
    "            mask_image=mask,\n",
    "            num_inference_steps=50,\n",
    "            strength=0.99,\n",
    "            guidance_scale=8.0,\n",
    "            height=image.height,\n",
    "            width=image.width\n",
    "        ).images[0]\n",
    "    else:\n",
    "        # SD 1.5 parameters\n",
    "        result = pipe(\n",
    "            prompt=\"empty room, clean walls, professional photography\",\n",
    "            negative_prompt=\"furniture, people, objects, low quality\",\n",
    "            image=image,\n",
    "            mask_image=mask,\n",
    "            num_inference_steps=50,\n",
    "            guidance_scale=7.5,\n",
    "            height=image.height,\n",
    "            width=image.width\n",
    "        ).images[0]\n",
    "    \n",
    "    print(\"✅ Inpainting complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title('Original', fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(mask, cmap='gray')\n",
    "axes[1].set_title('Mask', fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(result)\n",
    "model_name = \"SDXL\" if \"sdxl\" in MODEL_CHOICE else \"SD 1.5\"\n",
    "axes[2].set_title(f'{model_name} Result', fontsize=14)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save and download\n",
    "result.save(\"inpainted_result.png\")\n",
    "files.download(\"inpainted_result.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-pass refinement for even better quality\n",
    "def refine_result(image, mask, initial_result, num_passes=2):\n",
    "    \"\"\"Run multiple passes for refinement\"\"\"\n",
    "    result = initial_result\n",
    "    \n",
    "    for pass_num in range(1, num_passes):\n",
    "        print(f\"Refinement pass {pass_num}...\")\n",
    "        \n",
    "        # Use slightly different parameters for refinement\n",
    "        result = pipe(\n",
    "            prompt=\"high quality, photorealistic, professional\",\n",
    "            negative_prompt=\"artifacts, blurry\",\n",
    "            image=result,\n",
    "            mask_image=mask,\n",
    "            num_inference_steps=30,\n",
    "            strength=0.5,  # Lower strength for refinement\n",
    "            guidance_scale=5.0\n",
    "        ).images[0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Uncomment to use:\n",
    "# refined = refine_result(image, mask, result, num_passes=2)\n",
    "# refined.save(\"refined_result.png\")\n",
    "# files.download(\"refined_result.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing multiple images\n",
    "def process_batch(zip_path):\n",
    "    \"\"\"Process multiple image/mask pairs\"\"\"\n",
    "    import zipfile\n",
    "    import os\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall('batch')\n",
    "    \n",
    "    results = []\n",
    "    for file in os.listdir('batch'):\n",
    "        if file.startswith('image') and file.endswith('.png'):\n",
    "            img = Image.open(f'batch/{file}').convert('RGB')\n",
    "            mask_file = file.replace('image', 'mask')\n",
    "            \n",
    "            if os.path.exists(f'batch/{mask_file}'):\n",
    "                msk = Image.open(f'batch/{mask_file}').convert('L')\n",
    "                \n",
    "                print(f\"Processing {file}...\")\n",
    "                result = pipe(\n",
    "                    prompt=\"empty room, clean\",\n",
    "                    image=img,\n",
    "                    mask_image=msk,\n",
    "                    num_inference_steps=50\n",
    "                ).images[0]\n",
    "                \n",
    "                result.save(f'batch/result_{file}')\n",
    "                results.append(f'batch/result_{file}')\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Uncomment to use:\n",
    "# results = process_batch('your_batch.zip')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}